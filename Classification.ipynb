{
    "metadata": {
        "kernelspec": {
            "name": "python2-spark20", 
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python"
        }, 
        "language_info": {
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "name": "python", 
            "nbconvert_exporter": "python"
        }
    }, 
    "cells": [
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 1, 
            "source": "import pandas as pd\nfrom io import StringIO\nimport requests\nimport json\nimport pandas as pd\nfrom sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\nfrom matplotlib import pylab\nfrom sklearn.svm import LinearSVC\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nnp.random.seed(10) \n\n%matplotlib inline"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "[1 0 2 4 3]\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 2, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Material</th>\n      <th>Usura_mat_g</th>\n      <th>Durezza_Disco</th>\n      <th>Comprex_LP</th>\n      <th>Comprex_LR</th>\n      <th>Grindo_LP</th>\n      <th>Grindo_LR</th>\n      <th>PistoneCpx</th>\n      <th>Inerzia</th>\n      <th>Vmax</th>\n      <th>...</th>\n      <th>CodImpianto_13.0</th>\n      <th>CodImpianto_14.0</th>\n      <th>CodImpianto_15.0</th>\n      <th>Disco_nuovo_0</th>\n      <th>Disco_nuovo_1</th>\n      <th>Disco_256X22</th>\n      <th>Disco_256x22</th>\n      <th>Disco_276x24</th>\n      <th>Disco_280X22</th>\n      <th>Disco_280x22</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15.2</td>\n      <td>165</td>\n      <td>182</td>\n      <td>182</td>\n      <td>810</td>\n      <td>813</td>\n      <td>54</td>\n      <td>65</td>\n      <td>195</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>13.3</td>\n      <td>177</td>\n      <td>181</td>\n      <td>203</td>\n      <td>738</td>\n      <td>729</td>\n      <td>54</td>\n      <td>65</td>\n      <td>195</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>7.5</td>\n      <td>235</td>\n      <td>125</td>\n      <td>136</td>\n      <td>727</td>\n      <td>731</td>\n      <td>54</td>\n      <td>65</td>\n      <td>195</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>7.8</td>\n      <td>237</td>\n      <td>137</td>\n      <td>102</td>\n      <td>701</td>\n      <td>674</td>\n      <td>54</td>\n      <td>65</td>\n      <td>195</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>10.9</td>\n      <td>180</td>\n      <td>196</td>\n      <td>201</td>\n      <td>820</td>\n      <td>805</td>\n      <td>54</td>\n      <td>65</td>\n      <td>195</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 42 columns</p>\n</div>", 
                        "text/plain": "   Material  Usura_mat_g  Durezza_Disco  Comprex_LP  Comprex_LR  Grindo_LP  \\\n0         1         15.2            165         182         182        810   \n1         0         13.3            177         181         203        738   \n2         1          7.5            235         125         136        727   \n3         1          7.8            237         137         102        701   \n4         1         10.9            180         196         201        820   \n\n   Grindo_LR  PistoneCpx  Inerzia  Vmax      ...       CodImpianto_13.0  \\\n0        813          54       65   195      ...                      0   \n1        729          54       65   195      ...                      0   \n2        731          54       65   195      ...                      0   \n3        674          54       65   195      ...                      0   \n4        805          54       65   195      ...                      0   \n\n   CodImpianto_14.0  CodImpianto_15.0  Disco_nuovo_0  Disco_nuovo_1  \\\n0                 0                 0              1              0   \n1                 0                 0              1              0   \n2                 0                 0              1              0   \n3                 0                 0              1              0   \n4                 0                 0              1              0   \n\n   Disco_256X22  Disco_256x22  Disco_276x24  Disco_280X22  Disco_280x22  \n0             0             0             0             1             0  \n1             0             0             0             1             0  \n2             0             0             0             1             0  \n3             0             0             0             1             0  \n4             0             0             0             1             0  \n\n[5 rows x 42 columns]"
                    }
                }
            ], 
            "execution_count": 2, 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "(482, 2)\n[1 2 4 3 0]\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 3, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10240</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10241</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10244</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10246</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24583</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "       0  1\n0  10240  1\n1  10241  1\n2  10244  1\n3  10246  1\n4  24583  2"
                    }
                }
            ], 
            "execution_count": 3, 
            "source": "df_data_2 = pd.read_csv(get_object_storage_file_with_credentials_a860223228054eadb78455bad5266913('ITTProject', 'mapping.csv'), header = None)\nprint df_data_2.shape\nprint df_data_2[1].unique()\ndf_data_2.head()"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 4, 
            "source": "X = df_data_1.drop('Material', axis=1).values\nY = df_data_1['Material'].values\n\nX = (X - X.mean(axis=0))/ X.std(axis=0)\n"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": ""
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/bluemix_jupyter_bundle.v43/notebook/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 5, 
                    "data": {
                        "text/plain": "[<matplotlib.lines.Line2D at 0x7ff1780d3b50>]"
                    }
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEACAYAAACZLPCyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7ff178065650>"
                    }
                }
            ], 
            "execution_count": 5, 
            "source": "skf = StratifiedKFold(Y, n_folds=4)\n\nC = np.arange(70,2001, 10)\nweighted_M = np.zeros(C.shape)\nX_train = np.array([])\nX_test = np.array([])\ny_test = np.array([])\ny_train = np.array([])\nfor train_val_index, test_index in skf:\n    X_train, X_test = X[train_val_index], X[test_index]\n    y_train, y_test = Y[train_val_index], Y[test_index]\n\nskf_val = StratifiedKFold(y_train, n_folds=4)\nfor train_idx, val_idx in skf_val:\n    X_train_eff, X_val = X_train[train_idx], X_train[val_idx]\n    y_train_eff, y_val = y_train[train_idx], y_train[val_idx]\n    for c_idx, c in enumerate(C):                             \n        linear_ = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=c,\n                multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n                    class_weight='balanced', verbose=0, random_state=None, \n                        max_iter=1000).fit(X_train_eff, y_train_eff)\n        y_pred = linear_.predict(X_val)\n        weighted = f1_score(y_val, y_pred, average='weighted')\n        weighted_M[c_idx] = weighted_M[c_idx] + weighted \n\nweighted_M = weighted_M / C.shape[0]\nplt.scatter(C, weighted_M)\nplt.plot(C, weighted_M)"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "y_train (490, 5)\nx_train (490, 41)\nx_train_eff (3, 41)\nX_val (2, 41)\ny_train_eff (3, 5)\ny_val (2, 5)\n"
                }, 
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-23-748a0393de95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                         max_iter=1000).fit(X_train_eff, y_train_eff)\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v43/notebook/lib/python2.7/site-packages/sklearn/svm/classes.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m--> 205\u001b[1;33m                          dtype=np.float64, order=\"C\")\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v43/notebook/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    513\u001b[0m                         dtype=None)\n\u001b[0;32m    514\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v43/notebook/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mValueError\u001b[0m: bad input shape (3, 5)"
                    ], 
                    "ename": "ValueError", 
                    "evalue": "bad input shape (3, 5)"
                }
            ], 
            "execution_count": 23, 
            "source": "skf = StratifiedKFold(Y, n_folds=4)\n\nenc = OneHotEncoder(5)\nY_ohe = pd.get_dummies(Y).values\n\nC = np.arange(70,2001, 10)\nweighted_M = np.zeros(C.shape)\nX_train = np.array([])\nX_test = np.array([])\ny_test = np.array([])\ny_train = np.array([])\nfor train_val_index, test_index in skf:\n    X_train, X_test = X[train_val_index], X[test_index]\n    y_train, y_test = Y_ohe[train_val_index], Y_ohe[test_index]\nprint \"y_train\", y_train.shape\nprint \"x_train\", X_train.shape\nskf_val = StratifiedKFold(y_train[0], n_folds=4)\nfor train_idx, val_idx in skf_val:\n    X_train_eff, X_val = X_train[train_idx], X_train[val_idx]\n    y_train_eff, y_val = y_train[train_idx], y_train[val_idx]\n    print \"x_train_eff\", X_train_eff.shape\n    print \"X_val\", X_val.shape\n    print \"y_train_eff\", y_train_eff.shape\n    print \"y_val\", y_val.shape\n    for c_idx, c in enumerate(C):          \n\n        linear_ = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=c,\n                multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n                    class_weight='balanced', verbose=0, random_state=None, \n                        max_iter=1000).fit(X_train_eff, y_train_eff)\n        y_pred = linear_.predict(X_val)\n        weighted = log_loss(y_val, y_pred)\n        weighted_M[c_idx] = weighted_M[c_idx] + weighted \n\nweighted_M = weighted_M / C.shape[0]\nplt.scatter(C, weighted_M)\nplt.plot(C, weighted_M)"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 81, 
            "source": "X = df_data_1.drop('Material', axis=1).values\ny = df_data_1['Material'].values\n#X = (X - X.min(axis=0))/ (X.max(axis=0) - X.min(axis=0))\nK = Y_ohe.shape[1]\nD = X.shape[1]"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 85, 
            "source": "# initialize parameters randomly\nh = 100 # size of hidden layer\nW = 0.01 * np.random.randn(D,h)\nb = np.zeros((1,h))\nW2 = 0.01 * np.random.randn(h,K)\nb2 = np.zeros((1,K))\n\n# some hyperparameters\nstep_size = 1e-04\nreg = 1e-3 # regularization strength\n\n# gradient descent loop\nnum_examples = X.shape[0]\n"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "iteration 0: loss 1.767502\n"
                }
            ], 
            "execution_count": null, 
            "source": "for i in xrange(30000):\n\n    # evaluate class scores, [N x K]\n    hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation\n    scores = np.dot(hidden_layer, W2) + b2\n\n    # compute the class probabilities\n    exp_scores = np.exp(scores)\n    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n\n    # compute the loss: average cross-entropy loss and regularization\n    corect_logprobs = -np.log(probs[range(num_examples),y])\n    data_loss = np.sum(corect_logprobs)/num_examples\n    reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n    loss = data_loss + reg_loss\n\n    if i % 1000 == 0:\n        print \"iteration %d: loss %f\" % (i, loss)\n\n    # compute the gradient on scores\n    dscores = probs\n    dscores[range(num_examples),y] -= 1\n    dscores /= num_examples\n\n    # backpropate the gradient to the parameters\n    # first backprop into parameters W2 and b2\n    dW2 = np.dot(hidden_layer.T, dscores)\n    db2 = np.sum(dscores, axis=0, keepdims=True)\n    # next backprop into hidden layer\n    dhidden = np.dot(dscores, W2.T)\n    # backprop the ReLU non-linearity\n    dhidden[hidden_layer <= 0] = 0\n    # finally into W,b\n    dW = np.dot(X.T, dhidden)\n    db = np.sum(dhidden, axis=0, keepdims=True)\n\n    # add regularization gradient contribution\n    dW2 += reg * W2\n    dW += reg * W\n\n    # perform a parameter update\n    W += -step_size * dW\n    b += -step_size * db\n    W2 += -step_size * dW2\n    b2 += -step_size * db2"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "\n# evaluate training set accuracy\nscores = np.dot(X, W) + b\npredicted_class = np.argmax(scores, axis=1)\nprint 'training accuracy: %.2f' % (np.mean(predicted_class == y))"
        }
    ], 
    "nbformat_minor": 0, 
    "nbformat": 4
}